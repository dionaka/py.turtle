1.1新增简单配置保存功能
1.2增加提示词，修改了配置文件的bug
1.3替换os.system的音频播放部分，改用playsound，可内置播放
1.4(大更新)添加gui界面,删除了在命令窗口配置文件。添加live2d,手搓报错了估计几十次,预计后面会出一个inst
all.txt下载依赖项
1.5连接聊天与模型动画,实现当 AI 回复时,能够触发 Live2D 模型的说话或其他相应动画
1.51每次 AI 回复时，模型都有可能播放不同的动画(暂弃置）
1.52简单的关键词来触发模型的特定动画
1.6添加切换模型功能（报错几十次）
1.7增加了视角跟随鼠标
1.8增加了眨眼效果
1.9增加全屏跟随与ui可拖动
2.0增加了滚轮缩放
2.1兼容了vrm模型（弃了）chat2.0 - 副本(failed).py有半成品显示vrm模型贴图与简单动作感兴趣可以看看
待解决:
我因手电脑本地有simple_sovits训练好的模型(比我之前gpt_sovit和v2版本的速更快),而像小智机器人这种可以自定义本地服务器(自定义tts)的配置中只提供了gpt_sovits2及以上版本,所以之前我单独写过sample_api请求的部分代码,这次就直接拿来用了。但考虑到用户电脑上没有tts的本地api,我也不可能一个个主流api接收格式验证并写入代码(官方文档也解决不了问题,因为万一他依赖库更新就炸了,我又不能把依赖库一起整合打包太大了)。emm所以这有两种解决方案,一是网上找个免费tts,基础功能能跑就行,二是单独打包份本地api放网盘供有需要用户离线也可本地ttsc,但期末没时间整了。
待实装：
实现桌宠特有功能： 例如让窗口透明、可点击穿透（除模型区域）、可以拖动等，使其更像一个桌面宠物。
添加用户交互： 实现用户点击模型特定区域时，触发模型的反应或动画。
让模型的动画与聊天回复的内容更相关？（例如，根据回复的语气或关键词触发不同的动作）
实现唇形同步，让模型的嘴巴随着 TTS 语音移动？
考虑加vrm模型